# Supervised Learning Algorithms

1. **Linear Regression**
   - **Regressor**
   - For continuous variable prediction.
   - Concepts: objective function, gradient descent.

2. **Logistic Regression**
   - **Classifier**
   - For binary classification.
   - Concepts: sigmoid function, log-loss.

3. **k-Nearest Neighbors (k-NN)**
   - **Classifier** (can also be used as a regressor)
   - For classification and regression based on proximity.
   - Concepts: Euclidean distance, choosing \(k\).

4. **Decision Trees**
   - **Classifier** (can also be used as a regressor)
   - Iterative splitting of data.
   - Concepts: Gini impurity, entropy.

5. **Random Forest**
   - **Classifier** (can also be used as a regressor)
   - An ensemble of decision trees.
   - Concepts: bagging, out-of-bag error.

6. **Support Vector Machines (SVM)**
   - **Classifier** (can also be used as a regressor)
   - Classification by maximizing margins.
   - Concepts: kernel trick, margin maximization.

7. **Gradient Boosting (e.g., XGBoost, LightGBM)**
   - **Classifier** (can also be used as a regressor)
   - Powerful algorithms for classification/regression.
   - Concepts: boosting, overfitting control.

---

# Unsupervised Learning Algorithms

1. **k-Means Clustering**
   - **Unsupervised**
   - Data partitioning into clusters.
   - Concepts: centroids, optimizing \(k\).

2. **Principal Component Analysis (PCA)**
   - **Unsupervised**
   - Dimensionality reduction.
   - Concepts: eigenvalues, eigenvectors.

3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**
   - **Unsupervised**
   - Density-based clustering.
   - Concepts: eps (radius), minPts (minimum points).

4. **Hierarchical Clustering**
   - **Unsupervised**
   - Building a hierarchy of clusters.
   - Concepts: dendrogram, linkage methods.